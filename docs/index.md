## Abstract

While deep learning (DL)-based networked systems have shown great potential in various applications, a key drawback is that Deep Neural Networks (DNNs) in DL are blackboxes and nontransparent for network operators. The lack of interpretability makes DL-based networked systems challenging to operate and troubleshoot, which further prevents DL-based networked systems from deploying in practice. In this paper, we propose Metis, a novel framework to interpret DL-based networked systems for practical deployment. Metis categorizes current DL-based networked systems and introduces different explanation methods based on decision tree and hypergraph to effectively interpret DL-based networked systems. Metis can interpret the DNN policies in the form of decision trees and highlight critical components based on analysis over hypergraph. We evaluate Metis over several typical DL-based networked systems and demonstrate that Metis can provide human-readable explanations for network operators. We also present three use cases of Metis, which could (i) help network operators troubleshoot DL-based networked systems, (ii) improve the decision latency and resource consumption of DL-based networked systems by ~10x on different metrics, and (iii) provide suggestions on daily operations for network operators when incidences occur.

## Contact
For any questions, please send an email to [contact@transys.io](mailto:contact@transys.io).